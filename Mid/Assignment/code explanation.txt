**Import necessary libraries**

ðŸ“¦ import os
Purpose: Brings in Pythonâ€™s built-in os (Operating System) module.
ðŸ“¦ import numpy as np
Purpose: Imports NumPy, the core library for numerical operations in Python.
ðŸ“¦ import matplotlib.pyplot as plt
Purpose: Imports pyplot from Matplotlib, a popular plotting library.
ðŸ“¦ from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
Purpose: Brings specific metrics functions from Scikit-learn.
ðŸ“¦ import tensorflow as tf
Purpose: Loads TensorFlow, the deep learning library you'll use to build and train your model.
ðŸ“¦ from tensorflow.keras.preprocessing.image import ImageDataGenerator
Purpose: Brings in ImageDataGenerator from Keras inside TensorFlow.
ðŸ“¦ from tensorflow.keras.applications import DenseNet121
Purpose: Imports the DenseNet121 pre-trained model.
ðŸ“¦ from tensorflow.keras import layers, models
Purpose: Imports the layers (like Dense, Dropout, Flatten, etc.) and models (Sequential, Model) from Keras.



**Upload the path of google drive and set parameters**

ðŸ“‚ path = '/content/drive/MyDrive/dataset'
Purpose: Defines where your image dataset is located inside your mounted Google Drive.
ðŸ“ img_size = (224, 224)
Purpose: Sets the target size for resizing all images.
ðŸ“¦ batch_size = 32
Purpose: Defines how many images to process at once during training.
ðŸ”¥ epochs = 10
Purpose: Sets how many full passes through the training dataset you want.



**Data augmentation and preprocessing part**


ðŸ›  train_datagen = ImageDataGenerator(...)
Purpose: Creates a data loader that also preprocesses/augments images on the fly.

Settings inside it:

rescale=1./255: Normalizes pixel values from [0-255] to [0-1] â€” helps model training.

validation_split=0.3: Reserves 30% of the data for validation/testing, 70% for training.

horizontal_flip=True: Randomly flips images horizontally during training.

vertical_flip=True: Randomly flips images vertically too.


ðŸŽ¨ def to_grayscale(image):

return tf.image.rgb_to_grayscale(image)
Purpose: Defines a helper function to convert a color image into grayscale (1 channel).

ðŸŽ¨ def preprocess(image):
Purpose: Defines another helper function that:

Resizes image to 224Ã—224.

Converts it to grayscale (1 channel).

Converts grayscale back to 3 channels because pre-trained models like DenseNet expect 3 channels (RGB input).



ðŸšš train_generator = train_datagen.flow_from_directory(...)
Purpose: Actually loads the training images.

Details:

path: The folder path where images are stored.

target_size=img_size: Resizes every image to (224,224).

batch_size=batch_size: Loads 32 images at a time.

class_mode='binary': Since you have 2 classes (brain_tumor / non_brain_tumor).

subset='training': Only loads the 70% training set (because of the earlier 30% split).

shuffle=True: Randomizes the image order â€” good for training!





ðŸšš test_generator = train_datagen.flow_from_directory(...)
Purpose: Loads the validation/test images.

Details:

Same settings as train generator, except:

subset='validation': Loads the 30% validation (unseen) data.

shuffle=False: No shuffling because during evaluation you want consistent, repeatable results.




**Choose DenseNet121 model and create model**

ðŸ§  base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
Purpose: Loads a pre-trained DenseNet121 model.

Settings:

include_top=False: Don't load the original DenseNet's final classification layers â€” we will add our own custom head.

weights='imagenet': Load weights pre-trained on ImageNet (big image dataset).

input_shape=(224,224,3): Expect images resized to 224Ã—224 with 3 color channels.


ðŸ§Š base_model.trainable = False
Purpose: Freeze the DenseNet121 layers so that during training only your new layers are updated.






ðŸ—ï¸ model = models.Sequential([...])
Purpose: Build a new complete model by stacking layers sequentially.

Let's look inside:


Layer	Purpose
layers.Input(shape=(224, 224, 3))	Defines the input shape for the model.
layers.Lambda(preprocess)	Applies your custom grayscale preprocessing before feeding images to DenseNet.
base_model	DenseNet121 pre-trained feature extractor.
layers.GlobalAveragePooling2D()	Reduces the big feature maps to a single feature vector (makes it ready for Dense layers).
layers.Dense(256, activation='relu')	Adds a fully connected layer with 256 neurons and ReLU activation for non-linearity.
layers.Dropout(0.5)	Randomly turns off 50% of neurons during training to prevent overfitting.
layers.Dense(1, activation='sigmoid')	Final output layer: gives a single probability (0 to 1) for binary classification (brain tumor or not).


ðŸ› ï¸ model.compile(...)
Purpose: Sets up how the model will learn.

Settings:

optimizer='adam': A popular optimizer that adapts learning rates automatically.

loss='binary_crossentropy': Best choice for binary classification.

metrics=['accuracy']: Tracks accuracy during training and evaluation.



ðŸ§¾ model.summary()
Purpose: Prints a summary of all layers inside your model â€” very useful to verify your architecture is correct!



**The process of train the Model**

ðŸ‹ï¸â€â™‚ï¸ history = model.fit(...)
Purpose: This trains the model using the training data and evaluates it on the validation data.


Now inside fit(...):

Argument	Purpose
train_generator	Feeds the training images and labels (from your 70% training set) batch by batch.
epochs=epochs	Trains the model for the number of epochs you defined earlier (epochs=10).
validation_data=test_generator	After each epoch, evaluates the model performance on the 30% validation (test) set.



ðŸ“ˆ history
Type: A history object that stores:

training accuracy,

training loss,

validation accuracy,

validation loss



**Plot Training & Validation Accuracy**

ðŸŽ¨ plt.plot(history.history['accuracy'], label='Train Accuracy')
Purpose: Plots the training accuracy curve.

ðŸŽ¨ plt.plot(history.history['val_accuracy'], label='Test Accuracy')
Purpose: Plots the validation (test) accuracy curve.

ðŸ·ï¸ plt.xlabel('Epochs')
Purpose: Labels the X-axis as "Epochs" â€” number of training cycles.

ðŸ·ï¸ plt.ylabel('Accuracy')
Purpose: Labels the Y-axis as "Accuracy" â€” performance metric.

ðŸ·ï¸ plt.title('Training & Test Accuracy over Epochs')
Purpose: Sets a title for the plot to explain what the graph shows.

ðŸ“œ plt.legend()
Purpose: Displays the legend box so you can know which curve is train and which is test.

ðŸ› ï¸ plt.grid(True)
Purpose: Adds a background grid to the plot for easier reading of values.

ðŸ“ˆ plt.show()
Purpose: Finally displays the plot on the screen!





**Finally Evaluate the Model & it's Metrics**


ðŸŽ¯ y_pred_probs = model.predict(test_generator)
Purpose: Predicts the probability scores (between 0 and 1) for all images in the test set.

ðŸŽ¯ y_pred = (y_pred_probs > 0.5).astype(int).reshape(-1)
Purpose: Converts the predicted probabilities into class labels:

If >0.5 â†’ Class 1 (Tumor)

If â‰¤0.5 â†’ Class 0 (Non Tumor)


ðŸŽ¯ y_true = test_generator.classes
Purpose: Fetches the true labels (0 or 1) from the test data.

ðŸ“œ print("Classification Report:\n")
Purpose: Prints a title before the full classification report.

ðŸ“œ print(classification_report(y_true, y_pred, target_names=['Non Tumor', 'Tumor']))
Purpose: Prints detailed evaluation metrics:

Precision

Recall

F1-score

Support (number of true examples for each class)


  Metric                	 Meaning
---------                   ---------------
Precision	 Out of predicted positives, how many were correct?
Recall	         Out of actual positives, how many were captured?
F1-score	 Harmonic mean of precision and recall.



ðŸ”² cm = confusion_matrix(y_true, y_pred)
Purpose: Creates the Confusion Matrix showing:

True Positive

True Negative

False Positive

False Negative



ðŸ”² disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non Tumor', 'Tumor'])
Purpose: Prepares to plot the confusion matrix with class names instead of numbers.


ðŸ”² disp.plot(cmap=plt.cm.Blues)
Purpose: Actually plots the confusion matrix with a nice blue color theme.

ðŸ”² plt.title('Confusion Matrix')
Purpose: Adds a title above the confusion matrix plot.

ðŸ”² plt.show()
Purpose: Displays the confusion matrix.








